{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок теоретических вопросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Основное отличие DBSCAN и K-Means*: \n",
    "\n",
    "1.\tБлагодаря своей простой структуре K-Means обучается быстрее, чем DBSCAN\n",
    "2.\tDBSCAN  способен формировать кластеры любой формы, в то время как K-Means только определенной формы \n",
    "3.\tK-Means можно использовать для генерации новых признаков, а DBSCAN для этого неприменим\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** Методу DBSCAN важно, чтобы точки находились плотно друг к другу, а их форма и расположение центра не особо важно.\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*В чем состоит сложность при работе с DBSCAN*: \n",
    "\n",
    "1.\tСложен в обучении\n",
    "2.\tНеобходимо делать предположения о следующих двух параметрах: размер окрестности и количество соседей.\n",
    "3.\tНе учитывает, что в данных могут быть выбросы\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** По построению DBSCAN, в дейтсвительно, предполагает некоторые априорные представления об этих двух параметрах\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Какая задача напрямую не решается кластеризацией?*: \n",
    "\n",
    "1.\tПоиск похожих клиентов для рекомендательных систем\n",
    "2.\tПредсказание ВВП по заголовкам новостных источников \n",
    "3.\tВыделение групп похожих ответов в соц. опросах\n",
    "4.\tОбъединение сообществ в соц. сетях по тематикам\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** Предсказание ВВП - это задача обучения с учителем. Конечно, решая ее, можно использовать алгоритмы кластеризации, скажем, для создания новых категориальных признаков. Но напрямую кластеризировать ВВП не получится :)\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок практики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша задача - предсказать есть диабет у индивида или нет. В качестве таргета - колонка Diabetes. В нем три различных значения: `0`, `1`, `2`. `0` означает, что наблюдаемой здоров, `1` значит, что есть риск диабета, `2` означает наличие диабета. В качестве признаков будем использовать пол, количество лет в США, доход семьи и некоторые показатели, измеренные медицинскими работниками.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.** В этой части ДЗ попробуем использовать кластеризацию как инструмент при проведении моделирования в задаче классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Загрузим датасет\n",
    "\n",
    "df = pd.read_csv('datahw21.csv', index_col='Unnamed: 0')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Посмотрим как устроены данные\n",
    "### Изобразим корреляционную матрицу\n",
    "\n",
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df.corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Разделим выборку на трейн-тест\n",
    "\n",
    "data = df.drop(['Diabetes'], axis=1)\n",
    "target = df[['Diabetes']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                    target, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы использовать K-means, лучше будет отнормировать данные. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Воспользуемся StandardScaler\n",
    "\n",
    "cols = X_train.columns\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = pd.DataFrame(scaler.fit_transform(X_train), columns=cols)\n",
    "X_test_sc = pd.DataFrame(scaler.transform(X_test), columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим K-Means с параметрами `n_clusters` = 3, `tol` = 0.0005. Выбор параметров обусловлен тем, что у нас три возможных значения таргета. Но в целом основной подход подбора количества кластеров - по кривой зависимости внутрикластерного и межкластерного расстояний от количества кластеров.\n",
    "\n",
    "Установите `random_state` = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kms = KMeans(n_clusters = 3, \n",
    "             tol = 0.0005,\n",
    "             random_state=1)\n",
    "\n",
    "kms.fit_predict(X_train_sc)\n",
    "\n",
    "print (\"parameters: \", kms.get_params)\n",
    "print (\"preict: \", kms.predict)\n",
    "print (\"\\nscore: %.2f\" % kms.score(X_test_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем качество на изначальных данных(нормированных). Для этого обучите с дефолтными параметрами `RandomForestClassifier`, `LogisticRegression`, `LinearSVC`. Там, где нужно, установите `random_state` = 1. (1б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "lr = LogisticRegression()\n",
    "svm = LinearSVC()\n",
    "\n",
    "rf.fit(X_train_sc, y_train)\n",
    "lr.fit(X_train_sc, y_train)\n",
    "svm.fit(X_train_sc, y_train)\n",
    "\n",
    "print('RF acc:', accuracy_score(y_test, rf.predict(X_test_sc)))\n",
    "print('LR acc:',accuracy_score(y_test, lr.predict(X_test_sc)))\n",
    "print('SVM acc:',accuracy_score(y_test, svm.predict(X_test_sc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте в признаковое описание номер кластера и посчитайте качество с новым признаком! Стало ли качество хоть сколько-то лучше? (1б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_k = pd.concat(\n",
    "    [\n",
    "        X_train_sc,\n",
    "        pd.DataFrame(kms.predict(X_train_sc), columns=['Cluster_num'])   # <-- добавляем кластер как признак\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "X_test_k = pd.concat(\n",
    "    [X_test_sc,\n",
    "     pd.DataFrame(kms.predict(X_test_sc), columns=['Cluster_num'])       # <-- добавляем кластер как признак\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "lr = LogisticRegression()\n",
    "svm = LinearSVC()\n",
    "\n",
    "rf.fit(X_train_k, y_train)\n",
    "lr.fit(X_train_k, y_train)\n",
    "svm.fit(X_train_k, y_train)\n",
    "\n",
    "print('RF acc:', accuracy_score(y_test, rf.predict(X_test_k)))\n",
    "print('LR acc:',accuracy_score(y_test, lr.predict(X_test_k)))\n",
    "print('SVM acc:',accuracy_score(y_test, svm.predict(X_test_k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем расстояния от объектов до центров кластеров. Для этого воспользуемся методом `transform` обученного класса kmeans.\n",
    "\n",
    "Обучим и посчитаем метрики исключительно на расстояниях до центра. Убедимся, что такой подход имеет право на существование, если данные позволяют, то качество не сильно должно пострадать. А в каких-то случаях может оказаться даже лучше! Таким образом можно снижать размерность данных. (2б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1 = kms.transform(X_train_sc)            #  <--- расстояния от объектов до центра кластеров на трейне\n",
    "new2 = kms.transform(X_test_sc)             #  <--- расстояния от объектов до центра кластеров на трейне\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "lr = LogisticRegression()\n",
    "svm = LinearSVC()\n",
    "\n",
    "rf.fit(new1, y_train)\n",
    "lr.fit(new1, y_train)\n",
    "svm.fit(new1, y_train)\n",
    "\n",
    "print('RF acc:', accuracy_score(y_test, rf.predict(new2)))\n",
    "print('LR acc:',accuracy_score(y_test, lr.predict(new2)))\n",
    "print('SVM acc:',accuracy_score(y_test, svm.predict(new2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (Бонус)** Задача кластеризации может использоваться не только для специфических задач группировки данных, но и для оптимизации других методов. Вы уже знаете, что одна из основных проблем kNN в скорости его предсказания. В этом задании попробуем ускорить работу kNN с помощью кластеризации, не теряя при этом сильно в качестве.\n",
    "\n",
    "Сначала загрузим уже известные вам данные клиентов страховой компании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Загрузим известный нам датасет\n",
    "\n",
    "data = pd.read_csv('processed_vehicle_inssurance.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Разделим выборку на трейн-тест\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop('Response', axis=1)[:25000]\n",
    "y = data['Response'][:25000]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values,\n",
    "                                                    random_state=0,\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Нормируем данные\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите обычный kNN с одним соседом и измерьте качество, например, взвешенную f-меру, чтобы потом сранить с нашей реализацией. (1б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, roc_curve, auc\n",
    "print(f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша реализация на python работает медленнее по сравнению с библиотечным kNN. Однако реализация на более низкоуровневых языках программирования (C++) и на большом количестве данных данный метод на самом деле позволяет ускорять подсчет расстояний."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8db21564b35bbdf2f1295d2e540489014671416f5dc577a5b9d4ca56833a3713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
